import os
import sys
import time
import json
import shutil
import random
import psutil
import argparse
import threading
import traceback
import subprocess
import multiprocessing
from pathlib import Path
import concurrent.futures as cf
from contextlib import contextmanager, redirect_stdout, redirect_stderr
import glob

ROOT_PATH = '/tmp/llm4apr_validation/'

def clean_tmp_folder(tmp_dir):
    if os.path.isdir(tmp_dir) and tmp_dir.startswith(ROOT_PATH):
        shutil.rmtree(tmp_dir)
    os.makedirs(tmp_dir)


def strip_lines(lines):
    return [line.strip() for line in lines]


def encoding_check(encoding_check_file_path):
    if not os.path.exists(encoding_check_file_path):
        print(f"[ERROR] File does not exist: {encoding_check_file_path}")
        return 'utf-8', None  # è¿”å›é»˜è®¤ç¼–ç å’ŒNoneä½œä¸ºå†…å®¹
        
    file_content = None
    encoding_mode = 'utf-8'
    try:
        with open(encoding_check_file_path, 'r', encoding=encoding_mode) as f:
            file_content = f.read()
    except UnicodeDecodeError:
        encoding_mode = 'ISO-8859-1'
        with open(encoding_check_file_path, 'r', encoding=encoding_mode) as f:
            file_content = f.read()
    except Exception as e:
        print(f"[ERROR] read encoding_check FAILURE: {e}")
        return 'utf-8', None  # è¿”å›é»˜è®¤ç¼–ç å’ŒNoneä½œä¸ºå†…å®¹
    return encoding_mode, file_content


def checkout_defects4j_project(current_bug, project_dir):
    project, bug_id = current_bug.split('-')
    FNULL = open(os.devnull, 'w')
    command = "defects4j checkout " + " -p " + project + " -v " + bug_id + 'b'  + " -w " + project_dir
    print('[CHECKOUT]', command)
    
    # æ‰§è¡Œcheckoutå‘½ä»¤
    p = subprocess.Popen([command], shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    stdout, stderr = p.communicate()
    
    # æ£€æŸ¥å‘½ä»¤æ˜¯å¦æˆåŠŸæ‰§è¡Œ
    if p.returncode != 0:
        print(f"[ERROR] Checkout failed with return code {p.returncode}")
        print(f"[ERROR] stdout: {stdout}")
        print(f"[ERROR] stderr: {stderr}")
        return False
        
    # éªŒè¯é¡¹ç›®ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
    if not os.path.exists(project_dir):
        print(f"[ERROR] Project directory does not exist after checkout: {project_dir}")
        return False
        
    # æ£€æŸ¥srcç›®å½•æ˜¯å¦å­˜åœ¨
    src_dir = os.path.join(project_dir, 'src')
    if not os.path.exists(src_dir):
        print(f"[ERROR] Source directory does not exist after checkout: {src_dir}")
        return False
        
    print(f"[SUCCESS] Project checked out successfully to {project_dir}")
    return True


def monitor_memory(pid, interval, stop_event, max_memory_event):
    max_memory = 0
    try:
        main_proc = psutil.Process(pid)
        while not stop_event.is_set():
            procs = [main_proc] + main_proc.children(recursive=True)
            total_memory_usage = sum(proc.memory_info().rss for proc in procs if proc.is_running())
            max_memory = max(max_memory, total_memory_usage)
            time.sleep(interval)
    except psutil.NoSuchProcess:
        pass
    max_memory_event[0] = max_memory / (1024 ** 3)


def command_with_timeout(cmd, timeout=90):
    max_memory_event = [None]
    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    stop_event = threading.Event()
    monitor_thread = threading.Thread(target=monitor_memory, args=(process.pid, 1, stop_event, max_memory_event))
    try:
        monitor_thread.start()
        stdout, stderr = process.communicate(timeout=timeout)
    except subprocess.TimeoutExpired:
        ps_process = psutil.Process(process.pid)
        procs_kill = [ps_process] + ps_process.children(recursive=True)
        for proc in procs_kill:
            proc.kill()
        return 'TIMEOUT', 'TIMEOUT'
    finally:
        stop_event.set()
        monitor_thread.join()
        max_memory_usage = max_memory_event[0]
        if max_memory_usage and max_memory_usage > 6:
            print(f'[WARNING] MEMORY OCCUPIED {max_memory_usage:.2f} GB -- {cmd}')
    return stdout, stderr


def defects4j_test_suite(project_dir, timeout=1000):
    os.chdir(project_dir)
    out, err = command_with_timeout(["defects4j", "test", "-r"], timeout)
    if "Compilation failed" in str(out):
        print("[FAIL] Compile tests for ", project_dir)
    return out, err


def defects4j_export_trigger(project_dir, timeout=90):
    os.chdir(project_dir)
    out, err = command_with_timeout(["defects4j", "export", "-p", "tests.trigger"], timeout)
    return out, err


def defects4j_export_relevant(project_dir, timeout=90):
    os.chdir(project_dir)
    out, err = command_with_timeout(["defects4j", "export", "-p", "tests.relevant"], timeout)
    return out, err


def defects4j_test_one(project_dir, test_case, timeout=100):
    os.chdir(project_dir)
    out, err = command_with_timeout(["defects4j", "test", "-t", test_case], timeout)
    return out, err


def extract_d4j_result(err, out, val_stage):
    err_str, out_str = str(err), str(out)
    if 'TIMEOUT' in err_str or 'TIMEOUT' in out_str:
        correctness = 'TRIGGER_TIMEOUT' if val_stage == 'trigger' else 'RELEVANT_TIMEOUT'
    elif 'FAIL' in err_str or 'FAIL' in out_str:
        correctness = 'UNCOMPILABLE'
    elif "Failing tests: 0" in out_str:
        correctness = 'PLAUSIBLE'
    else:
        correctness = 'TRIGGER_ERROR' if val_stage == 'trigger' else 'RELEVANT_ERROR'
    return correctness




class ValTime:
    def __init__(self, val_start_time):
        self.val_start_timestamp = val_start_time
        
        self.val_init_time = 0
        self.val_overall_time = 0

        self.val_trigger_time = 0
        self.curr_trigger_time = 0
        self.trigger_start_timestamp = 0

        self.val_relevant_time = 0
        self.curr_relevant_time = 0
        self.relevant_start_timestamp = 0

        self.curr_overall_time = 0

    def set_init_time(self, init_timestamp):
        self.val_init_time = init_timestamp - self.val_start_timestamp

    def set_trigger_start_timestamp(self, trigger_start_timestamp):
        self.trigger_start_timestamp = trigger_start_timestamp
    
    def set_relevant_start_timestamp(self, relevant_start_timestamp):
        self.relevant_start_timestamp = relevant_start_timestamp

    def set_trigger_end_time(self, trigger_end_timestamp):
        self.curr_trigger_time = trigger_end_timestamp - self.trigger_start_timestamp
        self.val_trigger_time += self.curr_trigger_time
    
    def set_relevant_end_time(self, relevant_end_timestamp):
        self.curr_relevant_time = relevant_end_timestamp - self.relevant_start_timestamp
        self.val_relevant_time += self.curr_relevant_time
    
    def get_curr_overall_time(self):
        self.curr_overall_time = self.curr_trigger_time + self.curr_relevant_time
        return int(self.curr_overall_time)
    
    def set_overall_time(self, end_timestamp):
        self.val_overall_time = end_timestamp - self.val_start_timestamp
    
    def get_relevant_time(self):
        return int()
    
    def print_validation_time_info(self, curr_bug):
        print(f"[TIME INFO] PREPARE  = {int(self.val_init_time)}s")
        print(f"[TIME INFO] TRIGGER  = {int(self.val_trigger_time)}s")
        if self.val_relevant_time > 2:
            print(f"[TIME INFO] RELEVANT = {int(self.val_relevant_time)}s")
        print(f'[TIME INFO] TOTAL {curr_bug} -- {int(int(self.val_overall_time))}s')
        print('=' * 100)




class ValInfo():
    def __init__(self, candidate_patch):
        print(f"[DEBUG] Initializing ValInfo with: {candidate_patch[1].keys()}")
        self.unvrf_patches = candidate_patch
        self.curr_bug = candidate_patch[0]
        patch_info = candidate_patch[1]
        self.patches = patch_info['patches']
        self.patch_info = {
            'loc': patch_info['loc'],
            'start': patch_info['start'],
            'end': patch_info['end']
        }
        
        # åˆå§‹åŒ–å…¶ä»–å±æ€§
        self.patch_id = 0
        self.validated_result = []
        self.overall_patch_status = 'failure'

        # æŒ‰é¡ºåºè°ƒç”¨åˆå§‹åŒ–å‡½æ•°
        self.init_buggy_project()
        self.init_bug_status_info()
        self.init_extract_project_info()

    def init_buggy_project(self):
        self.validation_path = ROOT_PATH
        self.proj_dir = os.path.join(self.validation_path, self.curr_bug)
        clean_tmp_folder(self.proj_dir)
        config_path = os.path.join(self.validation_path, 'config.json')
        with open(config_path, 'r') as f:
            config_info = json.load(f)

        self.val_result_path = os.path.join('defects4j/results/', config_info['model_id'])
        checkout_defects4j_project(self.curr_bug, self.proj_dir)

    def init_extract_project_info(self):
        self.buggy_file_path = os.path.join(self.proj_dir, self.patch_info['loc'])
        self.encoding_mode, self.original_buggy_file_content = encoding_check(self.buggy_file_path)
        
        # å¦‚æœæ–‡ä»¶å†…å®¹ä¸ºNoneï¼Œè¯´æ˜æ–‡ä»¶ä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥
        if self.original_buggy_file_content is None:
            print(f"[ERROR] Failed to read or find file: {self.buggy_file_path}")
            return False
        
        self.backup_buggy_file_path = f'{self.buggy_file_path}.llm4apr_backup'
        try:
            shutil.copyfile(self.buggy_file_path, self.backup_buggy_file_path)
        except Exception as e:
            print(f"[ERROR] Failed to create backup file: {e}")
            return False
        
        return True
    
    
    def check_init_success(self):
        return len(self.failed_test_cases) > 0
    
    
    def patch_id_counter(self):
        self.patch_id += 1


    def update_patch_val_result(self, patch_validation_info):
        self.validated_result.append(patch_validation_info)

    
    def save_validation_results(self, done=False):
        if not done and len(self.validated_result) % 10 != 0:
            return
        filename = str(self.curr_bug) + '-validated.jsonl'
        log_file = os.path.join(self.val_result_path, filename)
        if not os.path.exists(self.val_result_path):
            os.makedirs(self.val_result_path, exist_ok=True)
        try:   
            with open(log_file, "w") as f: 
                json.dump(self.validated_result, f, indent=2)
        except Exception as e:
            print('[ERROR] write_results_to_file: ', e)  


    def init_bug_status_info(self):
        """åˆå§‹åŒ–bugçš„æµ‹è¯•çŠ¶æ€ä¿¡æ¯"""
        print(f"[DEBUG] Initializing bug status for {self.curr_bug}")
        
        # è·å–è§¦å‘bugçš„æµ‹è¯•ç”¨ä¾‹
        out, err = defects4j_export_trigger(self.proj_dir)
        self.trigger_tests = []
        if out:
            self.trigger_tests = [line.strip() for line in str(out).split('\n') if line.strip()]
        
        # è·å–ç›¸å…³çš„æµ‹è¯•ç”¨ä¾‹
        out, err = defects4j_export_relevant(self.proj_dir)
        self.relevant_tests = []
        if out:
            self.relevant_tests = [line.strip() for line in str(out).split('\n') if line.strip()]
        
        # è¿è¡Œåˆå§‹æµ‹è¯•å¥—ä»¶ï¼Œç¡®è®¤bugçŠ¶æ€
        init_out, _ = defects4j_test_suite(self.proj_dir)
        self.failed_test_cases = []
        if init_out:
            self.failed_test_cases = [test.strip() for test in str(init_out).split(' - ')[1:]]
        
        print(f"[DEBUG] Found {len(self.trigger_tests)} trigger tests and {len(self.relevant_tests)} relevant tests")



        
class PatchValidation():
    def __init__(self, patch_code):
        self.patch_code = patch_code
        self.patch_status = 'UNVERIFIED'
        self.failing_test = {
            'TRIGGER' : [],
            'RELEVANT' : [],
            'TIMEOUT' : [],
        }
        self.patch_val_info = {}

    def apply_patch(self, bug_info, proj_dir, encoding_mode):
        bug_path = bug_info['loc']
        start_loc = bug_info['start']
        end_loc = bug_info['end']
        patch = self.patch_code.strip()
        buggy_full_path = os.path.join(proj_dir, bug_path)        
        with open(buggy_full_path, 'r', encoding=encoding_mode) as file:
            orig_buggy_code = file.readlines()
        with open(buggy_full_path, 'w', encoding=encoding_mode, errors='ignore') as file:
            patched = False
            for idx, line in enumerate(orig_buggy_code):
                if start_loc - 1 <= idx <= end_loc -1:
                    if not patched:
                        file.write(patch)
                        patched = True
                else:
                    file.write(line)
            assert patched, f'[ERROR] [ASSERT FAILURE] insert_fix_into_src not pateced'

    
    def trigger_test_validation(self, trigger_tests, proj_dir):
        for trigger in trigger_tests:
            if self.patch_status == 'UNVERIFIED' or self.patch_status == 'PLAUSIBLE':
                out, err = defects4j_test_one(proj_dir, trigger)
                self.patch_status = extract_d4j_result(err, out, 'trigger')
                if self.patch_status == 'TRIGGER_ERROR': 
                    self.failing_test['TRIGGER'].append(trigger)
                elif self.patch_status == 'TRIGGER_TIMEOUT':
                    self.failing_test['TIMEOUT'].append(trigger)


    def relevant_test_validation(self, proj_dir):
        if self.patch_status != 'PLAUSIBLE':
            return
        out, err = defects4j_test_suite(proj_dir)
        self.patch_status = extract_d4j_result(err, out, 'relevant')
        self.failing_test['RELEVANT'] = [test_case.strip() for test_case in str(out).split(' - ')[1:]]
    
    
    def print_curr_patch_status(self, curr_bug, curr_overall_time):
        status_color = {
            'PLAUSIBLE': '\033[92m',  # ç»¿è‰²
            'UNCOMPILABLE': '\033[91m',  # çº¢è‰²
            'TRIGGER_ERROR': '\033[93m',  # é»„è‰²
            'TRIGGER_TIMEOUT': '\033[93m',
            'RELEVANT_ERROR': '\033[93m',
            'RELEVANT_TIMEOUT': '\033[93m'
        }
        end_color = '\033[0m'
        
        color = status_color.get(self.patch_status, '')
        status_line = f'[PATCH STATUS] | {curr_bug:20} | {color}{self.patch_status:16}{end_color} | {curr_overall_time:4}s  |'
        print(status_line)
        
        # æ„å»ºæ—¥å¿—æ¶ˆæ¯
        log_messages = [status_line.replace(color, '').replace(end_color, '')]
        
        if self.patch_status == 'PLAUSIBLE':
            msg = f'[SUCCESS] Patch {curr_bug} passed all tests! ğŸ‰'
            print(msg)
            log_messages.append(msg)
        elif self.patch_status == 'UNCOMPILABLE':
            msg = f'[FAILED] Patch {curr_bug} failed to compile âŒ'
            print(msg)
            log_messages.append(msg)
        elif 'TIMEOUT' in self.patch_status:
            msg = f'[TIMEOUT] Patch {curr_bug} timed out â°'
            print(msg)
            log_messages.append(msg)
        elif 'ERROR' in self.patch_status:
            if self.failing_test['TRIGGER']:
                msg = f'[FAILED] Failed trigger tests: {", ".join(self.failing_test["TRIGGER"])} âŒ'
                print(msg)
                log_messages.append(msg)
            if self.failing_test['RELEVANT']:
                msg = f'[FAILED] Failed relevant tests: {", ".join(self.failing_test["RELEVANT"])} âŒ'
                print(msg)
                log_messages.append(msg)
        
        separator = '-' * 100
        print(separator)
        log_messages.append(separator)
        
        return '\n'.join(log_messages)
        
        
    def recover_buggy_file(self, backup_buggy_file_path, orig_file_content, patch_id, encoding_mode, proj_dir):
        if '.llm4apr_backup' not in backup_buggy_file_path:
            print(f'[ERROR] .llm4apr_backup not in backup_file')
            return
        
        recover_buggy_path = backup_buggy_file_path.replace('.llm4apr_backup', '')
        patched_backup_file_path = f'{recover_buggy_path}_{patch_id}_{self.patch_status}'
        
        # æ·»åŠ æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
        if not os.path.exists(recover_buggy_path):
            print(f'[WARNING] Source file not found: {recover_buggy_path}')
            return
        
        try:
            # å°è¯•ç§»åŠ¨æ–‡ä»¶
            if os.path.exists(recover_buggy_path):
                shutil.move(recover_buggy_path, patched_backup_file_path)
            
            # å¤åˆ¶å¤‡ä»½æ–‡ä»¶
            if os.path.exists(backup_buggy_file_path):
                shutil.copyfile(backup_buggy_file_path, recover_buggy_path)
                
                # éªŒè¯æ–‡ä»¶å†…å®¹
                with open(recover_buggy_path, 'r', encoding=encoding_mode) as f:
                    file_content = f.read()
                    if orig_file_content != file_content:
                        print(f'[ERROR] File content mismatch after recovery')
                        return
                    
                # æ¸…ç†ç¼–è¯‘æ–‡ä»¶
                if proj_dir.startswith(ROOT_PATH):
                    rm_class_filename = os.path.basename(recover_buggy_path).replace('.java', '.class')
                    root_dir = Path(proj_dir)
                    for file in root_dir.rglob(rm_class_filename):
                        try:
                            file.unlink()
                        except Exception as e:
                            print(f'[WARNING] Failed to remove class file: {e}')
                else:
                    print(f'[ERROR] Invalid project directory: {proj_dir}')
                
        except Exception as e:
            print(f'[ERROR] Failed to recover file: {str(e)}')
            traceback.print_exc()

    def summarize_patch_info(self, bug_name):
        self.patch_val_info = {
            'patch_code': self.patch_code, 
            'patch_status': self.patch_status, 
            'failing_tests': self.failing_test,
            'val_cnt' : 1,
            'bug_name' : bug_name
        }
        return self.patch_val_info
        



def get_result_paths(fixed_dir, json_file):
    base_path = os.path.join(fixed_dir, json_file)
    log_path = f"{base_path}.judgelog"
    result_path = f"{base_path}.result"
    return log_path, result_path

def load_cached_result(log_path, result_path):
    """å°è¯•åŠ è½½ç¼“å­˜çš„éªŒè¯ç»“æœ"""
    if os.path.exists(result_path) and os.path.exists(log_path):
        with open(result_path, 'r') as f:
            result = json.load(f)
        with open(log_path, 'r') as f:
            log = f.read()
        print(f"[CACHE] Found cached validation result")
        return result, log
    return None, None

def save_validation_result(log_path, result_path, results, log_content):
    """ä¿å­˜éªŒè¯ç»“æœå’Œæ—¥å¿—"""
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    os.makedirs(os.path.dirname(result_path), exist_ok=True)
    
    print(f"[DEBUG] Saving results to:")
    print(f"[DEBUG] - Log: {log_path}")
    print(f"[DEBUG] - Result: {result_path}")
    
    try:
        with open(result_path, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"[DEBUG] Successfully saved result file")
    except Exception as e:
        print(f"[ERROR] Failed to save result file: {str(e)}")
        print(f"[DEBUG] Current working directory: {os.getcwd()}")
        print(f"[DEBUG] Result path exists: {os.path.exists(os.path.dirname(result_path))}")
        raise
        
    try:
        with open(log_path, 'w') as f:
            f.write(log_content)
        print(f"[DEBUG] Successfully saved log file")
    except Exception as e:
        print(f"[ERROR] Failed to save log file: {str(e)}")
        raise

def validate_patches_per_bug(candidate_patch):
    bug_name, patch_info = candidate_patch
    patches = patch_info['patches']
    total_patches = len(patches)
    
    print(f"\n{'='*50}")
    print(f"[VALIDATING] {bug_name} - Testing {total_patches} patches")
    print(f"{'='*50}")
    
    # æ‰“å°è°ƒè¯•ä¿¡æ¯
    print(f"[DEBUG] Original JSON path: {patch_info['original_json']}")
    print(f"[DEBUG] Directory: {os.path.dirname(patch_info['original_json'])}")
    
    # æ„å»ºæ—¥å¿—å­—ç¬¦ä¸²
    validation_log = []
    validation_log.append(f"Validating {bug_name} with {total_patches} patches\n")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„ç»“æœ
    log_path, result_path = get_result_paths(os.path.dirname(patch_info['original_json']), f"{bug_name}.json")
    
    # æ‰“å°æœ€ç»ˆè·¯å¾„
    print(f"[DEBUG] Final paths:")
    print(f"[DEBUG] - Log: {log_path}")
    print(f"[DEBUG] - Result: {result_path}")
    cached_result, cached_log = load_cached_result(log_path, result_path)
    if cached_result is not None:
        print(cached_log)
        return cached_result
    
    val_time = ValTime(time.time())
    val_info = ValInfo(candidate_patch)
    if not val_info.check_init_success():
        return
    val_time.set_init_time(time.time())
    
    patch_results = []
    for i, curr_patch_code in enumerate(val_info.patches, 1):
        patch_log = f"\n[TESTING] Patch {i}/{total_patches} for {bug_name}\n"
        print(patch_log)
        validation_log.append(patch_log)
        
        val_info.patch_id_counter()
        patch_val = PatchValidation(curr_patch_code)
        
        patch_val.apply_patch(val_info.patch_info, val_info.proj_dir, val_info.encoding_mode)
        
        val_time.set_trigger_start_timestamp(time.time())
        patch_val.trigger_test_validation(val_info.trigger_tests, val_info.proj_dir)
        val_time.set_trigger_end_time(time.time())

        val_time.set_relevant_start_timestamp(time.time())
        patch_val.relevant_test_validation(val_info.proj_dir)
        val_time.set_relevant_end_time(time.time())    

        status_log = patch_val.print_curr_patch_status(val_info.curr_bug, val_time.get_curr_overall_time())
        validation_log.append(status_log)
        
        patch_val.recover_buggy_file(val_info.backup_buggy_file_path, val_info.original_buggy_file_content, \
                                     val_info.patch_id, val_info.encoding_mode, val_info.proj_dir)

        curr_patch_summary = patch_val.summarize_patch_info(val_info.curr_bug)
        print(f"[DEBUG] Patch validation result: {curr_patch_summary['patch_status']}")  # è°ƒè¯•ä¿¡æ¯
        patch_results.append(curr_patch_summary)
        val_info.update_patch_val_result(curr_patch_summary)
        val_info.save_validation_results()
    
    # ä¿å­˜éªŒè¯ç»“æœå’Œæ—¥å¿—
    save_validation_result(log_path, result_path, patch_results, '\n'.join(validation_log))
    return patch_results
    

class ValidationStats:
    def __init__(self):
        self.total_bugs = 0
        self.bug_results = {}  # å­˜å‚¨æ¯ä¸ªbugçš„æ‰€æœ‰è¡¥ä¸ç»“æœ
    
    def update(self, bug_id, patch_results):
        """
        æ›´æ–°bugçš„éªŒè¯ç»“æœ
        patch_results: è¯¥bugçš„æ‰€æœ‰è¡¥ä¸éªŒè¯ç»“æœåˆ—è¡¨
        """
        # print(f"[DEBUG] Updating stats for {bug_id} with {len(patch_results)} patches")
        self.total_bugs += 1
        self.bug_results[bug_id] = patch_results
    
    def get_success_rate(self):
        """è®¡ç®—Top-1ã€Top-5å’ŒTop-10çš„æˆåŠŸç‡"""
        if self.total_bugs == 0:
            return 0.0, 0.0, 0.0
        
        top1_success = 0
        top5_success = 0
        top10_success = 0
        
        # æ·»åŠ è¯¦ç»†ä¿¡æ¯æ‰“å°
        print(f"\n[DEBUG] è®¡ç®—æˆåŠŸç‡è¯¦æƒ…:")
        print(f"[DEBUG] æ€»bugæ•°é‡: {self.total_bugs}")
        
        for bug_id, patches in self.bug_results.items():
            if patches is None:
                # print(f"[DEBUG] {bug_id}: è·³è¿‡(patchesä¸ºNone)")
                continue
            
            # è®°å½•æ¯ä¸ªbugçš„ä¿®å¤æƒ…å†µ
            success_position = None
            for i, p in enumerate(patches, 1):
                if p is not None and p['patch_status'] == 'PLAUSIBLE':
                    success_position = i
                    break
                
            if success_position is not None:
                # print(f"[DEBUG] {bug_id}: åœ¨ç¬¬{success_position}ä¸ªpatchä¿®å¤æˆåŠŸ")
                if success_position == 1:
                    top1_success += 1
                if success_position <= 5:
                    top5_success += 1
                if success_position <= 10:
                    top10_success += 1
            # else:
            #     print(f"[DEBUG] {bug_id}: æœªä¿®å¤")
        
        print(f"[DEBUG] Top-1æˆåŠŸæ•°: {top1_success}")
        print(f"[DEBUG] Top-5æˆåŠŸæ•°: {top5_success}")
        print(f"[DEBUG] Top-10æˆåŠŸæ•°: {top10_success}")
        
        top1_rate = (top1_success / self.total_bugs) * 100
        top5_rate = (top5_success / self.total_bugs) * 100
        top10_rate = (top10_success / self.total_bugs) * 100
        
        return top1_rate, top5_rate, top10_rate

def load_previous_results(model_id):
    """åŠ è½½ä¹‹å‰éªŒè¯è¿‡çš„ç»“æœ"""
    results_dir = f'defects4j/results/{model_id}'
    previous_results = {}
    
    # åŠ è½½æ—¶é—´ä¿¡æ¯
    bug_dates = {}
    try:
        with open('defects4j/time.jsonl', 'r') as f:
            for line in f:
                data = json.loads(line)
                bug_id, date = list(data.items())[0]
                bug_dates[bug_id] = date
    except Exception as e:
        print(f"[WARNING] Failed to load time.jsonl: {e}")
    
    # ç”¨äºç»Ÿè®¡æ¯ä¸ªbugçš„è¡¥ä¸çŠ¶æ€
    status_summary = []
    
    # éå†æ‰€æœ‰å·²éªŒè¯çš„ç»“æœæ–‡ä»¶
    for json_file in glob.glob(os.path.join(results_dir, '*-validated.jsonl')):
        try:
            bug_id = os.path.basename(json_file).replace('-validated.jsonl', '')
            with open(json_file, 'r') as f:
                results = json.load(f)
                if results:  # ç¡®ä¿ç»“æœä¸ä¸ºç©º
                    previous_results[bug_id] = results
                    
                    # æ£€æŸ¥è¡¥ä¸çŠ¶æ€
                    plausible_found = False
                    for idx, patch in enumerate(results, 1):
                        if patch['patch_status'] == 'PLAUSIBLE':
                            plausible_found = True
                            status_summary.append({
                                'bug_id': bug_id,
                                'date': bug_dates.get(bug_id, 'N/A'),  # æ·»åŠ æ—¥æœŸä¿¡æ¯
                                'status': 'PLAUSIBLE',
                                'position': idx,
                                'total_patches': len(results)
                            })
                            break
                    
                    if not plausible_found:
                        status_summary.append({
                            'bug_id': bug_id,
                            'date': bug_dates.get(bug_id, 'N/A'),  # æ·»åŠ æ—¥æœŸä¿¡æ¯
                            'status': 'FAILED',
                            'position': None,
                            'total_patches': len(results)
                        })
                    
                    # print(f"[INFO] Loaded previous results for {bug_id}")
        except Exception as e:
            print(f"[WARNING] Failed to load previous results from {json_file}: {e}")
    
    # æ‰“å°è¯¦ç»†çš„çŠ¶æ€æ‘˜è¦
    print("\n[PREVIOUS VALIDATION SUMMARY]")
    print("=" * 100)
    print(f"{'Bug ID':15} | {'Date':10} | {'Status':10} | {'Position':10} | {'Total Patches':15}")
    print("-" * 100)
    
    for item in sorted(status_summary, key=lambda x: x['bug_id']):
        position_str = f"{item['position']}/{item['total_patches']}" if item['position'] else "N/A"
        status_color = '\033[92m' if item['status'] == 'PLAUSIBLE' else '\033[91m'
        print(f"{item['bug_id']:15} | {item['date']:10} | {status_color}{item['status']:10}\033[0m | {position_str:10} | {item['total_patches']:15}")
    
    print("=" * 100)
    print(f"Total previously validated bugs: {len(previous_results)}")
    print(f"Successfully fixed bugs: {len([x for x in status_summary if x['status'] == 'PLAUSIBLE'])}")
    print()
    
    return previous_results

def validate_defects4j(model_id, n_generations):
    stats = ValidationStats()
    candidate_patches = {}
    
    # é¦–å…ˆåŠ è½½ä¹‹å‰çš„éªŒè¯ç»“æœ
    previous_results = load_previous_results(model_id)
    print(f"[INFO] Loaded {len(previous_results)} previously validated bugs")
    
    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    for bug_id, results in previous_results.items():
        stats.update(bug_id, results)
    top1, top5, top10 = stats.get_success_rate()
    print("\n[FINAL SUCCESS RATE]")
    print(f"Top-1:  {top1:.2f}%")
    print(f"Top-5:  {top5:.2f}%")
    print(f"Top-10: {top10:.2f}%")
    
    # åŠ è½½æ‰€æœ‰è¡¥ä¸
    for i in range(n_generations):
        fix_dir = os.path.join('results', str(model_id), f'fixed{i}')
        if not os.path.exists(fix_dir):
            print(f"Warning: {fix_dir} does not exist")
            continue
            
        for json_file in glob.glob(os.path.join(fix_dir, '*.json')):
            if json_file.endswith('.log'):
                continue
                
            bug_id = os.path.basename(json_file).replace('.json', '')
            # è·³è¿‡å·²ç»éªŒè¯è¿‡çš„bug
            if bug_id in previous_results:
                continue
                
            if bug_id not in candidate_patches:
                candidate_patches[bug_id] = {
                    'patches': [],
                    'original_json': json_file
                }
                
            with open(json_file) as f:
                patch_info = json.load(f)
                if 'fix' in patch_info:
                    candidate_patches[bug_id]['patches'].append(patch_info['fix'])
                    candidate_patches[bug_id]['loc'] = patch_info['loc']
                    candidate_patches[bug_id]['start'] = patch_info['start']
                    candidate_patches[bug_id]['end'] = patch_info['end']
    
    # è¿‡æ»¤æ‰è¡¥ä¸æ•°é‡ä¸è¶³10ä¸ªçš„bug
    filtered_candidates = {}
    skipped_bugs = []
    for bug_id, patch_info in candidate_patches.items():
        if len(patch_info['patches']) >= 10:
            filtered_candidates[bug_id] = patch_info
        else:
            skipped_bugs.append((bug_id, len(patch_info['patches'])))
    
    # æ‰“å°è¿‡æ»¤ä¿¡æ¯
    if skipped_bugs:
        print("\n[SKIPPED BUGS] (insufficient patches)")
        print(f"{'Bug ID':20} | {'Patch Count':12}")
        print("-" * 35)
        for bug_id, count in sorted(skipped_bugs):
            print(f"{bug_id:20} | {count:12}")
        print(f"\nTotal skipped: {len(skipped_bugs)} bugs")
    
    # æ˜¾ç¤ºå¾…éªŒè¯çš„bugæ•°é‡
    remaining_bugs = len(filtered_candidates)
    print(f"\n[INFO] Found {remaining_bugs} new bugs with 10+ patches to validate")
    print(f"[INFO] Total bugs (including previous): {len(previous_results) + remaining_bugs}")
    
    if remaining_bugs == 0:
        print("[INFO] No new bugs to validate")
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        top1, top5, top10 = stats.get_success_rate()
        print("\n[FINAL SUCCESS RATE]")
        print(f"Top-1:  {top1:.2f}%")
        print(f"Top-5:  {top5:.2f}%")
        print(f"Top-10: {top10:.2f}%")
        return

    # åˆ›å»ºçº¿ç¨‹æ± 
    max_workers = min(multiprocessing.cpu_count(), 4)  # é™åˆ¶æœ€å¤§çº¿ç¨‹æ•°
    print(f"[INFO] Using {max_workers} workers for parallel validation")
    
    validated_count = 0
    total_count = len(filtered_candidates)
    results_lock = threading.Lock()
    
    with cf.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_bug = {
            executor.submit(validate_patches_per_bug, (bug_name, patch_info)): bug_name 
            for bug_name, patch_info in sorted(filtered_candidates.items())
        }
        
        for future in cf.as_completed(future_to_bug):
            bug_name = future_to_bug[future]
            try:
                results = future.result()
                
                with results_lock:
                    validated_count += 1
                    stats.update(bug_name, results)
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    top1, top5, top10 = stats.get_success_rate()
                    print(f"\n[CURRENT PROGRESS] Validated {validated_count}/{total_count} bugs")
                    print(f"[CURRENT SUCCESS RATE] Top-1: {top1:.2f}% | Top-5: {top5:.2f}% | Top-10: {top10:.2f}%")
                    print("=" * 100)
                    
            except Exception as e:
                print(f"Exception when validating {bug_name}: {str(e)}")
                traceback.print_exc()
    
    # æœ€ç»ˆç»Ÿè®¡
    top1, top5, top10 = stats.get_success_rate()
    print("\n[FINAL SUCCESS RATE]")
    print(f"Top-1:  {top1:.2f}%")
    print(f"Top-5:  {top5:.2f}%")
    print(f"Top-10: {top10:.2f}%")
    print("=" * 100)
    
    print('[END VALIDATION]')
    sys.stdout.flush()
    time.sleep(3)
    return

@contextmanager
def log_or_print(log_mode, log_path):
    if log_mode:
        with open(log_path, 'a') as log_file, redirect_stdout(log_file), redirect_stderr(log_file):
            yield
    else:
        yield

def shuffle_validated_patches(candidate_patches):
    items = list(candidate_patches.items())
    random.shuffle(items)
    shuffled_patches = {key: value for key, value in items}
    return shuffled_patches

def load_and_compare_results(model_id1, model_id2, min_patches=1):
    """åŠ è½½å¹¶å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„éªŒè¯ç»“æœ"""
    # åŠ è½½æ—¶é—´ä¿¡æ¯
    bug_dates = {}
    try:
        with open('time.jsonl', 'r') as f:
            for line in f:
                data = json.loads(line)
                bug_id, date = list(data.items())[0]
                bug_dates[bug_id] = date
    except Exception as e:
        print(f"[WARNING] Failed to load time.jsonl: {e}")

    # åŠ è½½ä¸¤ä¸ªæ¨¡å‹çš„ç»“æœ
    results1 = load_previous_results(model_id1)
    results2 = load_previous_results(model_id2)
    
    # è¿‡æ»¤åªä¿ç•™æœ‰10ä¸ªè¡¥ä¸çš„ç»“æœ
    filtered_results1 = {bug_id: results for bug_id, results in results1.items() 
                        if len(results) >= min_patches}
    filtered_results2 = {bug_id: results for bug_id, results in results2.items() if len(results) >= min_patches}
    
    # ä»patch_infoä¸­è·å–é•¿åº¦ä¿¡æ¯
    bug_lengths = {}
    for bug_id in filtered_results1.keys() | filtered_results2.keys():
        json_file = os.path.join('results', model_id1, 'fixed0', f'{bug_id}.json')
        try:
            with open(json_file, 'r') as f:
                patch_info = json.load(f)
                total_length = len(patch_info.get('title', '')) + len(patch_info.get('description', '')) + len(patch_info.get('buggy', ''))
                bug_lengths[bug_id] = total_length
        except Exception as e:
            print(f"[WARNING] Failed to load patch info for {bug_id}: {e}")
    
    # æ‰¾åˆ°æ‰€æœ‰å‡ºç°è¿‡çš„bugå’Œå…±åŒçš„bug
    all_bugs = sorted(set(filtered_results1.keys()) | set(filtered_results2.keys()))
    common_bugs = set(filtered_results1.keys()) & set(filtered_results2.keys())
    
    # æ‰“å°åˆå¹¶çš„è¡¨æ ¼
    print("\n[VALIDATION COMPARISON SUMMARY]")
    print("=" * 145)  # å¢åŠ æ€»å®½åº¦
    print(f"{'Bug ID':20} | {'Date':10} | {'Length':8} | {model_id1:^15} | {model_id2:^15} | {'Notes':20}")
    print("-" * 145)  # å¢åŠ åˆ†éš”çº¿å®½åº¦
    
    for bug_id in all_bugs:
        date = bug_dates.get(bug_id, 'N/A')
        length = bug_lengths.get(bug_id, 'N/A')
        if length != 'N/A':
            length = f"{length:,}"  # æ·»åŠ åƒä½åˆ†éš”ç¬¦
        
        # è·å–æ¨¡å‹1çš„ç»“æœ
        status1 = "N/A"
        position1 = ""
        if bug_id in filtered_results1:
            results = filtered_results1[bug_id]
            for idx, patch in enumerate(results, 1):
                if patch['patch_status'] == 'PLAUSIBLE':
                    status1 = f"PLAUSIBLE({idx})"
                    break
            if status1 == "N/A":
                status1 = "FAILED"
        
        # è·å–æ¨¡å‹2çš„ç»“æœ
        status2 = "N/A"
        position2 = ""
        if bug_id in filtered_results2:
            results = filtered_results2[bug_id]
            for idx, patch in enumerate(results, 1):
                if patch['patch_status'] == 'PLAUSIBLE':
                    status2 = f"PLAUSIBLE({idx})"
                    break
            if status2 == "N/A":
                status2 = "FAILED"
        
        # ç¡®å®šæ³¨é‡Š
        notes = ""
        if status1 == "N/A" and status2 != "N/A":
            notes = f"Only in {model_id2}"
        elif status1 != "N/A" and status2 == "N/A":
            notes = f"Only in {model_id1}"
        elif 'PLAUSIBLE' in status1 and 'PLAUSIBLE' in status2:
            notes = "Fixed by both"
        elif 'PLAUSIBLE' in status1:
            notes = f"Only fixed by {model_id1}"
        elif 'PLAUSIBLE' in status2:
            notes = f"Only fixed by {model_id2}"
        
        # è®¾ç½®é¢œè‰²
        status1_color = '\033[92m' if 'PLAUSIBLE' in status1 else '\033[91m' if status1 == 'FAILED' else '\033[0m'
        status2_color = '\033[92m' if 'PLAUSIBLE' in status2 else '\033[91m' if status2 == 'FAILED' else '\033[0m'
        
        print(f"{bug_id:20} | {date:10} | {length:>8} | {status1_color}{status1:^15}\033[0m | {status2_color}{status2:^15}\033[0m | {notes:20}")
    
    print("=" * 145)  # å¢åŠ åº•éƒ¨åˆ†éš”çº¿å®½åº¦
    
    # è®¡ç®—ä¿®å¤ç»Ÿè®¡
    fixed_bugs1 = {bug_id for bug_id, results in filtered_results1.items() 
                  if any(patch['patch_status'] == 'PLAUSIBLE' for patch in results)}
    fixed_bugs2 = {bug_id for bug_id, results in filtered_results2.items() 
                  if any(patch['patch_status'] == 'PLAUSIBLE' for patch in results)}
    
    common_fixed_bugs = fixed_bugs1 & fixed_bugs2
    only_fixed_by_1 = fixed_bugs1 - fixed_bugs2
    only_fixed_by_2 = fixed_bugs2 - fixed_bugs1
    
    # æ‰“å°è¯¦ç»†ä¿¡æ¯
    print(f"\n[DATA COVERAGE]")
    print(f"Model {model_id1} total bugs with 10 patches: {len(filtered_results1)}")
    print(f"Model {model_id2} total bugs with 10 patches: {len(filtered_results2)}")
    print(f"Common bugs with 10 patches: {len(common_bugs)}")
    
    print(f"\n[FIX STATISTICS]")
    print(f"Model {model_id1} fixed total: {len(fixed_bugs1)}")
    print(f"Model {model_id2} fixed total: {len(fixed_bugs2)}")
    print(f"Fixed by both models: {len(common_fixed_bugs)}")
    print(f"Only fixed by {model_id1}: {len(only_fixed_by_1)} {sorted(only_fixed_by_1)}")
    print(f"Only fixed by {model_id2}: {len(only_fixed_by_2)} {sorted(only_fixed_by_2)}")
    
    # è¿”å›è¿‡æ»¤åçš„ç»“æœç”¨äºç»Ÿè®¡
    filtered_stats1 = ValidationStats()
    filtered_stats2 = ValidationStats()
    
    for bug_id in common_bugs:
        if bug_id in filtered_results1:
            filtered_stats1.update(bug_id, filtered_results1[bug_id])
        if bug_id in filtered_results2:
            filtered_stats2.update(bug_id, filtered_results2[bug_id])
    
    return filtered_stats1, filtered_stats2

def print_comparison_results(stats1, stats2, model_id1, model_id2):
    """æ‰“å°å¯¹æ¯”ç»“æœ"""
    print("\n[COMPARISON RESULTS]")
    print("=" * 80)
    print(f"{'Metric':15} | {model_id1:>10} | {model_id2:>10} | {'Diff':>10}")
    print("-" * 80)
    
    top1_1, top5_1, top10_1 = stats1.get_success_rate()
    top1_2, top5_2, top10_2 = stats2.get_success_rate()
    
    metrics = [
        ("Top-1", top1_1, top1_2),
        ("Top-5", top5_1, top5_2),
        ("Top-10", top10_1, top10_2)
    ]
    
    for metric_name, val1, val2 in metrics:
        diff = val2 - val1
        diff_str = f"{diff:+.2f}%" if diff != 0 else "0.00%"
        color = '\033[92m' if diff > 0 else '\033[91m' if diff < 0 else '\033[0m'
        print(f"{metric_name:15} | {val1:>9.2f}% | {val2:>9.2f}% | {color}{diff_str:>10}\033[0m")
    
    print("=" * 80)
    print(f"Total bugs compared: {stats1.total_bugs}")

if __name__ == '__main__':
    start_val_time = time.time()

    parser = argparse.ArgumentParser()
    parser.add_argument('-m', type=str, required=True, help='model id')
    parser.add_argument('-m2', type=str, help='second model id for comparison')
    parser.add_argument('-n', type=int, required=True, help='number of generations to validate')
    parser.add_argument('--show-only', action='store_true', help='only show existing results without new validation')
    args = parser.parse_args()
    
    model_id = args.m
    results_dir = f'defects4j/results/{model_id}'
    output_result_dir = os.path.join(results_dir, 'validated')

    if args.show_only:
        # åŠ è½½å¹¶æ¯”è¾ƒç»“æœ
        filtered_stats1, stats2 = load_and_compare_results(args.m, args.m2)
        
        if args.m2:
            print_comparison_results(filtered_stats1, stats2, args.m, args.m2)
        else:
            # åªæ˜¾ç¤ºå•ä¸ªæ¨¡å‹çš„ç»“æœ
            top1, top5, top10 = filtered_stats1.get_success_rate()
            print("\n[FINAL SUCCESS RATE]")
            print(f"Top-1:  {top1:.2f}%")
            print(f"Top-5:  {top5:.2f}%")
            print(f"Top-10: {top10:.2f}%")
        sys.exit(0)

    # ç»§ç»­æ‰§è¡ŒåŸæœ‰çš„éªŒè¯é€»è¾‘
    validation_tmp_path = ROOT_PATH
    validation_config_path = os.path.join(validation_tmp_path, 'config.json')
    
    # ä»resultsç›®å½•è¯»å–æ‰€æœ‰ç”Ÿæˆçš„ä¿®å¤
    candidate_patches = {}
    for i in range(args.n):
        fixed_dir = os.path.join(results_dir, f'fixed{i}')
        if not os.path.exists(fixed_dir):
            print(f"Warning: {fixed_dir} does not exist")
            continue
            
        for json_file in os.listdir(fixed_dir):
            if not json_file.endswith('.json') or json_file.endswith('.log'):
                continue
            with open(os.path.join(fixed_dir, json_file), 'r') as f:
                fix_data = json.load(f)
                bug_name = json_file.replace('.json', '')
                if bug_name not in candidate_patches:
                    candidate_patches[bug_name] = {
                        'patches': [],
                        'loc': fix_data['loc'],
                        'start': fix_data['start'],
                        'end': fix_data['end']
                    }
                candidate_patches[bug_name]['patches'].append(fix_data['fix'])

    os.makedirs(validation_tmp_path, exist_ok=True)
    with open(validation_config_path, 'w') as f:
        json.dump({'model_id': model_id}, f, indent=2)

    os.makedirs(output_result_dir, exist_ok=True)
    validate_defects4j(model_id, args.n)
    print(f'[TIME INFO] total_time = {int(time.time() - start_val_time)} s')
